{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2d97960-0bb0-49d8-840a-016604a24ce4",
   "metadata": {},
   "source": [
    "# AI and ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429c30d-fefe-4407-a25c-96be32e7930f",
   "metadata": {},
   "source": [
    "## 1. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57553e1-dabe-49be-8b4d-78f757c90062",
   "metadata": {},
   "source": [
    "[TensorFlow](https://www.tensorflow.org/) is a machine learning environment. It can be used to used to identify and sort pictures as shown in the example below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f4f78-efd6-43b4-b942-43254695c153",
   "metadata": {},
   "source": [
    "### 1.1. Image processing using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297273ef-b03f-4979-b6e5-80568d5753b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install Python packages\n",
    "# pip install tensorflow\n",
    "# pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6a4216-a84c-427c-9b8e-a767b22ebc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86876db-1208-4af1-bd8b-90ea83953692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 07:41:28.471852: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Load the model directly from TensorFlow Hub with error handling\n",
    "try:\n",
    "    detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    detector = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5b4118-d6c9-4c2b-ab14-43d87c9e0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_humans(image_path):\n",
    "    \"\"\"Detects humans in a given image.\"\"\"\n",
    "    if not detector:\n",
    "        print(\"Model not loaded. Cannot process images.\")\n",
    "        return False\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load image at {image_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Convert BGR to RGB \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert to float tensor\n",
    "        input_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        \n",
    "        # Run inference\n",
    "        detections = detector(input_tensor)\n",
    "        \n",
    "        # Extract detection results\n",
    "        classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "        scores = detections['detection_scores'][0].numpy()\n",
    "        \n",
    "        # Check for humans (class ID 1 is person in COCO dataset)\n",
    "        # Filter for high confidence detections\n",
    "        human_indices = np.where((classes == 1) & (scores > 0.5))[0]\n",
    "        \n",
    "        return len(human_indices) > 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1fa2f29-d63a-4dda-989c-e050547063b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_csv):\n",
    "    \"\"\"Process all images in a folder recursively and save results to CSV.\"\"\"\n",
    "    processed_count = 0\n",
    "    human_count = 0\n",
    "    \n",
    "    # Open CSV file for writing\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow(['Image Path'])\n",
    "        \n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Check if file is an image\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    processed_count += 1\n",
    "                    \n",
    "                    try:\n",
    "                        if detect_humans(full_path):\n",
    "                            csv_writer.writerow([full_path])\n",
    "                            human_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {full_path}: {e}\")\n",
    "    \n",
    "    print(f\"\\nProcessed {processed_count} images.\")\n",
    "    print(f\"Found humans in {human_count} images.\")\n",
    "    print(f\"Results saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe7dc59-24e3-4fa7-87db-4837228dd3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6 images.\n",
      "Found humans in 4 images.\n",
      "Results saved to output/human_detection_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_folder = \"../media/training-data/\"\n",
    "output_csv = \"output/human_detection_results.csv\"\n",
    "process_folder(image_folder, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844889b-0d70-43ea-aa28-92bbb7b2ecd0",
   "metadata": {},
   "source": [
    "### 1.2. Use file location from text file to copy to another location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9138e2fa-3230-4405-9e5d-36f325c767d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b927306-1373-4acc-9d44-178d0b2b2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(source_paths, destination_base):\n",
    "    # Create destination directory if it doesn't exist\n",
    "    os.makedirs(destination_base, exist_ok=True)\n",
    "    \n",
    "    # Keep track of copied files and any errors\n",
    "    successful_copies = []\n",
    "    failed_copies = []\n",
    "    \n",
    "    for source_path in source_paths:\n",
    "        try:\n",
    "            # Clean up the path and get the filename\n",
    "            source_path = source_path.strip()\n",
    "            filename = os.path.basename(source_path)\n",
    "            \n",
    "            # Create destination path\n",
    "            destination_path = os.path.join(destination_base, filename)\n",
    "            \n",
    "            # Handle duplicate filenames by adding a number if necessary\n",
    "            counter = 1\n",
    "            while os.path.exists(destination_path):\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                destination_path = os.path.join(destination_base, f\"{name}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "            \n",
    "            # Copy the file\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "            successful_copies.append(filename)\n",
    "            print(f\"Successfully copied: {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_copies.append((filename, str(e)))\n",
    "            print(f\"Failed to copy {filename}: {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Successfully copied {len(successful_copies)} files\")\n",
    "    if failed_copies:\n",
    "        print(f\"Failed to copy {len(failed_copies)} files:\")\n",
    "        for filename, error in failed_copies:\n",
    "            print(f\"- {filename}: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2adbb0c0-a9f2-475a-9f56-3af728ad1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file paths from CSV\n",
    "csv_file = \"output/human_detection_results.csv\"\n",
    "try:\n",
    "    # Read the CSV file - assuming the paths are in the first column\n",
    "    # If they're in a different column, you'll need to specify the column name\n",
    "    df = pd.read_csv(csv_file)\n",
    "    source_paths = df.iloc[:, 0].tolist()  # Gets the first column\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {str(e)}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57c8b9c-3297-4c57-861c-d74b921761c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination directory\n",
    "destination_base = \"destination/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0dc72e-e694-450d-8ba6-97bee2243a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied: nathan-anderson-FHiJWoBodrs-unsplash.jpg\n",
      "Successfully copied: ryoji-iwata-X53e51WfjlE-unsplash.jpg\n",
      "Successfully copied: Watts_George_Frederick_Portrait_Of_The_Artists_Wife_Mary.jpg\n",
      "Successfully copied: Alvígio_de_Barros_França_(dedé)_(1)_-_1-20725-0000-0000,_Acervo_do_Museu_Paulista_da_USP.jpg\n",
      "\n",
      "Summary:\n",
      "Successfully copied 4 files\n"
     ]
    }
   ],
   "source": [
    "# Run the copy operation\n",
    "copy_images(source_paths, destination_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736602a7-00e3-4fc5-957d-276a49a42455",
   "metadata": {},
   "source": [
    "## 2. Run your large language models locally with Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6dd8a-f6d9-4f82-8e78-1f3e0ffe99ad",
   "metadata": {},
   "source": [
    "Check the [docs of Ollama](https://github.com/ollama/ollama/tree/main/docs) to install Ollama locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce02c7b-476e-452c-af41-78036a3c657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After having installed Ollama you can install ollama packages for Python\n",
    "## \"ollama run llama3.2:1b\" will pull and run a light version of llama3.2 \n",
    "# pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e4c1f4-5959-405b-93f4-d09cec26bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bff1d58-a4bb-44ea-82b3-5b74546e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file path\n",
    "output_file = \"output/image_analysis_results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06001200-5be5-40df-aea6-4c5081bf8d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing nathan-anderson-FHiJWoBodrs-unsplash.jpg\n",
      "Finished processing ryoji-iwata-X53e51WfjlE-unsplash.jpg\n",
      "Finished processing Watts_George_Frederick_Portrait_Of_The_Artists_Wife_Mary.jpg\n"
     ]
    }
   ],
   "source": [
    "# Open the output file in append mode\n",
    "with open(output_file, \"a\") as f:\n",
    "  # Write header row\n",
    "  f.write(\"Filename, Has People?, Execution Time (minutes)\\n\")\n",
    "\n",
    "  # Get all image files in the ai-playground folder\n",
    "  for filename in os.listdir(\"../media/training-data/\"):\n",
    "      image_path = os.path.join(\"../media/training-data/\", filename)\n",
    "\n",
    "      # Capture start time\n",
    "      start_time = time.time()\n",
    "\n",
    "      # Perform image analysis using Llama\n",
    "      response = ollama.chat(\n",
    "          model='llama3.2-vision',\n",
    "          messages=[{\n",
    "              'role': 'user',\n",
    "              'content': 'Tell me whether there are people in this image. A simple yes/no is enough.',\n",
    "              'images': [image_path]\n",
    "          }]\n",
    "      )\n",
    "\n",
    "      # Calculate execution time\n",
    "      end_time = time.time()\n",
    "      execution_time = round((end_time - start_time) / 60, 2)\n",
    "\n",
    "      # Extract people presence from response\n",
    "      has_people = \"Yes\" if response[\"message\"][\"content\"] == \"Yes\" else \"No\"\n",
    "\n",
    "      # Write results to file\n",
    "      f.write(f\"{filename}, {has_people}, {execution_time}\\n\")\n",
    "\n",
    "      print(f\"Finished processing {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac5c0e-c420-491e-bf3d-0b16cf152fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
